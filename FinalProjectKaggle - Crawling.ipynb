{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2647e7c6",
   "metadata": {},
   "source": [
    "# First Step - Crawling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61803734",
   "metadata": {},
   "source": [
    "In this file we are crawling from the website kaggle.\n",
    "We used selenium for the crawling because the website uses JavaScript code to render their pages.\n",
    "Our crawling fetches the data from 3 main sources:\n",
    "1. From each page of the website we fetch the links to every DataSet.\n",
    "2. From each DataSet we fetch the following data:\n",
    "    1. The dataset's title -> the title of the dataset\n",
    "    2. The dataset's subtitle -> the subtitle of the dataset\n",
    "    3. The dataset's author -> the name of the author that created the dataset\n",
    "    4. The dataset's Version -> the number of the latest version of the dataset\n",
    "    5. The dataset's date of the last update -> when the author updated the dataset for the last time \n",
    "    6. The dataset's Rating -> the number of upvotes that the dataset gets\n",
    "    7. The dataset's Usability -> the quality of the dataset documantation and tables\n",
    "    8. The dataset's amount of file -> the number of files that the dataset has\n",
    "    9. The dataset's size -> the weight of all the files \n",
    "    10. The dataset's views -> the amount of people that entered the dataset's page \n",
    "    11. The dataset's downloads -> the amount of people that downloaded the dataset's files\n",
    "    12. The dataset's topics -> the amount of open dicussions about the dataset\n",
    "3. From each Dataset's author we fetch the following data:\n",
    "    1. The author's experience -> the seniority of the author\n",
    "    2. The author's following -> the number of people that the author follows\n",
    "    3. The author's followers -> the number of people that follow the author\n",
    "    4. The author's discussions -> the number of discussions that the author started/ participated in\n",
    "    5. The author's competitions -> the number of competitive competitions that the author attended\n",
    "    6. The author's location -> the geographic location of the author \n",
    "    7. The author's code -> the number of updates that the author contributed to other datasets\n",
    "    8. The author's datasets -> the number of datasets that the author owns.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8625a9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbfa151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9660b",
   "metadata": {},
   "source": [
    "# Our main crawling function\n",
    "### param: \n",
    "* num_of_page_start - the first page that the crawling will get the data from\n",
    "* num_of_page_end - the last page that the crawling will get the data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8997c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data_of_database(num_of_page_start,num_of_page_end):\n",
    "    #\n",
    "    # 1.we created a list for each type of data (column)\n",
    "    #\n",
    "    dataSetTitle = []\n",
    "    dataSetSubTitle = []\n",
    "    dataSetAuthorName = []\n",
    "    dataSetVersion = []\n",
    "    dataSetDateNum = []\n",
    "    dataSetDateNumType = []\n",
    "    dataSetRating = []\n",
    "    dataSetUsability = []\n",
    "    dataSetFileCount = []\n",
    "    dataSetFileSize = []\n",
    "    dataSetFileSizeType = []\n",
    "    dataSetViewCount = []\n",
    "    dataSetDownloadNum = []\n",
    "    dataSetNotebookNum = []\n",
    "    dataSetTopicNum = []\n",
    "    dataSetAuthorDiscussionCount = []\n",
    "    dataSetAuthorCompetitiveCount = []\n",
    "    dataSetAuthorDatasetCount = []\n",
    "    dataSetAuthorCodeCount = []\n",
    "    dataSetAuthorFollowers = []\n",
    "    dataSetAuthorFollowing = []\n",
    "    dataSetAuthorLocation = []\n",
    "    dataSetAuthorExperienceNum = []\n",
    "    dataSetAuthorExperienceType = []\n",
    "    \n",
    "    for page in range(num_of_page_start,num_of_page_end+1):\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        #\n",
    "        # 2.for each page we fetch the links of the datasets and put them into the 'links' list.\n",
    "        #\n",
    "        driver.get(f'https://www.kaggle.com/datasets?page={page}')\n",
    "        time.sleep(3)\n",
    "        i=0\n",
    "        data = driver.find_element(By.XPATH, \"//ul[@class='km-list km-list--three-line']\").find_elements(By.XPATH, './/li')\n",
    "        links =[]\n",
    "        for li in data:\n",
    "            links.append(li.find_elements(By.XPATH, './/div')[0].find_element(By.XPATH, './/a').get_attribute('href'))\n",
    "        #\n",
    "        #3. for each link we start to fetch the data from the dataset page\n",
    "        #\n",
    "        for link in links:\n",
    "            driver.get(link)\n",
    "            time.sleep(3)\n",
    "            #####################################################THE DATASET DATA##############################\n",
    "            title = driver.find_element(By.XPATH,\"//h1[@class='dataset-header-v2__title']\").text #The Dataset Title\n",
    "            try:\n",
    "                #The Dataset subTitle\n",
    "                subtitle = driver.find_element(By.XPATH,\"//h2[@class='dataset-header-v2__subtitle']\").text\n",
    "            except:\n",
    "                subtitle=None\n",
    "            author = driver.find_element(By.XPATH,\"//div[@class='dataset-header-v2__details']\")\n",
    "            authorLink = author.find_element(By.XPATH,\"//a[@class='dataset-header-v2__owner-name']\") #The link to the author page\n",
    "            authorName = author.text.split(\"•\")[0].split(\"\\n\")[0] # The Author Name\n",
    "            try:\n",
    "                date = author.text.split(\"•\")[1].split(\"(\")\n",
    "                version = date[1].split(\")\")[0].split(\" \")[1] # The version of the dataset\n",
    "                date = date[0].split(\"  updated \")[1].split(\" \")\n",
    "                if(date[0]=='an' or date[0]=='a'): # the date of the dataset's last update \n",
    "                    dateNum=1\n",
    "                    dateNumType = date[1]\n",
    "                else:\n",
    "                    dateNum=date[0]\n",
    "                    dateNumType=date[1][:-1]\n",
    "            except:\n",
    "                dateNum=0\n",
    "                dateNumType=None\n",
    "                version=1\n",
    "            date = date[0] # the date of dataset\n",
    "            data = driver.find_element(By.XPATH, \"//ul[@class='horizontal-list']\").find_elements(By.XPATH, './/li')\n",
    "            rating = driver.find_element(By.XPATH,\"//span[@role='button']\").text #the number of Upvotes \n",
    "            usability = driver.find_element(By.XPATH,\"//p[@data-test='rating']\").text #the usability rank\n",
    "            try:\n",
    "                file = driver.find_elements(By.XPATH,\"//h6\")[1].find_element(By.XPATH,'..//p').text.split(\" \")\n",
    "                #number of files\n",
    "                fileCount = driver.find_elements(By.XPATH,\"//h6\")[2].find_element(By.XPATH,'..//p').text.split(\" \")[0]\n",
    "                fileSize = file[0] #the size of all the files\n",
    "                fileSizeType = file[1] # the size type of the files -> kb,mb,gb.....\n",
    "            except:\n",
    "                fileCount=0\n",
    "                fileSize=None\n",
    "                fileSizeType =None\n",
    "            viewC = data[0].text.split(\" \")[0] #the number of people that view the dataset\n",
    "            downloadNum=data[1].text.split(\" \")[0] #the number of people that download the dataset\n",
    "            notebookNum=data[2].text.split(\" \")[0] #the number of updates that people contributed to the dataset\n",
    "            topicNum = data[3].text.split(\" \")[0] #the number of topics of the dataset\n",
    "            #\n",
    "            #4. switching to the author page to fetch his data\n",
    "            #\n",
    "            authorLink.click()\n",
    "            time.sleep(2)\n",
    "            #####################################################THE AUTHOR DATA##############################\n",
    "            followData = driver.find_elements(By.XPATH,\".//div[@class='profile__user-followers-item']\")\n",
    "            userData = driver.find_element(By.XPATH,\".//div[@class='pageheader__nav-wrapper']\")    \n",
    "            try:\n",
    "                #the amount of datasets that the author has\n",
    "                authorDatasetCount = userData.find_element(By.XPATH,\".//a[@title='datasets']\").find_element(By.XPATH,\".//span[@class='pageheader__link-count']\").find_element(By.XPATH,\".//span\").text\n",
    "                rankOfAuthor = driver.find_element(By.XPATH,\".//a[@title='Progression']\").find_elements(By.XPATH,\".//p\")[1].text # the rank of the author\n",
    "                authorExperience = driver.find_element(By.XPATH,\".//p[@class='profile__user-metadata']\").find_element(By.XPATH,\".//span\").text.split(\" \") #the experience of the author\n",
    "                authorExperienceNum =authorExperience[0] #the number of days/month/years of experience\n",
    "                authorExperienceType = authorExperience[1] #the number type of the experience -> days/month/years \n",
    "            except:\n",
    "                authorDatasetCount = None\n",
    "                rankOfAuthor =None\n",
    "                authorExperienceNum = 0\n",
    "                authorExperienceType =None\n",
    "            try:\n",
    "                #the amount of competitive competitions that the author has\n",
    "                authorCompetitiveCount = userData.find_element(By.XPATH,\".//a[@title='competitions']\").find_element(By.XPATH,\".//span[@class='pageheader__link-count']\").find_element(By.XPATH,\".//span\").text\n",
    "            except:\n",
    "                authorCompetitiveCount=0\n",
    "            try:\n",
    "                #the amount of code updates that the author contributed to the site\n",
    "                authorCodeCount = userData.find_element(By.XPATH,\".//a[@title='code']\").find_element(By.XPATH,\".//span[@class='pageheader__link-count']\").find_element(By.XPATH,\".//span\").text\n",
    "            except:\n",
    "                authorCodeCount=0\n",
    "            try:\n",
    "                #the amount of discussions that the author has joined\n",
    "                authorDiscussionCount = userData.find_element(By.XPATH,\".//a[@title='discussion']\").find_element(By.XPATH,\".//span[@class='pageheader__link-count']\").find_element(By.XPATH,\".//span\").text\n",
    "            except:\n",
    "                authorDiscussionCount =0\n",
    "            try:\n",
    "                authorFollowers = followData[0].text.split(\"s\")[1]\n",
    "            except:\n",
    "                authorFollowers=0\n",
    "            try:\n",
    "                authorFollowing = followData[1].text.split(\"g\")[1]\n",
    "            except:\n",
    "                authorFollowing=0\n",
    "            try:\n",
    "                authorLocation = driver.find_element(By.XPATH,\".//p[@class='profile__user-location']\").text # the location of the author\n",
    "            except:\n",
    "                authorLocation=None\n",
    "                \n",
    "            ##############################adding to the lists##########################\n",
    "            #\n",
    "            #5. adding the data of the current dataset into their list\n",
    "            #\n",
    "            dataSetTitle.append(title)\n",
    "            dataSetSubTitle.append(subtitle)\n",
    "            dataSetAuthorName.append(authorName)\n",
    "            dataSetVersion.append(version)\n",
    "            dataSetDateNum.append(dateNum)\n",
    "            dataSetDateNumType.append(dateNumType)\n",
    "            dataSetRating.append(rating)\n",
    "            dataSetUsability.append(usability)\n",
    "            dataSetFileCount.append(fileCount)\n",
    "            dataSetFileSize.append(fileSize)\n",
    "            dataSetFileSizeType.append(fileSizeType)\n",
    "            dataSetViewCount.append(viewC)\n",
    "            dataSetDownloadNum.append(downloadNum)\n",
    "            dataSetNotebookNum.append(notebookNum)\n",
    "            dataSetTopicNum.append(topicNum)\n",
    "            dataSetAuthorDiscussionCount.append(authorDiscussionCount)\n",
    "            dataSetAuthorCompetitiveCount.append(authorCompetitiveCount)\n",
    "            dataSetAuthorDatasetCount.append(authorDatasetCount)\n",
    "            dataSetAuthorCodeCount.append(authorCodeCount)\n",
    "            dataSetAuthorFollowers.append(authorFollowers)\n",
    "            dataSetAuthorFollowing.append(authorFollowing)\n",
    "            dataSetAuthorLocation.append(authorLocation)\n",
    "            dataSetAuthorExperienceNum.append(authorExperienceNum)\n",
    "            dataSetAuthorExperienceType.append(authorExperienceType)\n",
    "    #\n",
    "    #6. converting the lists into a DataFrame\n",
    "    #\n",
    "    df= pd.DataFrame({\"Title\":dataSetTitle,\"SubTitle\":dataSetSubTitle,\"Version\":dataSetVersion,\"Date Num\":dataSetDateNum,\"Date Type\":dataSetDateNumType,\n",
    "        \"Usability\":dataSetUsability,\"Rating\":dataSetRating,\"Views\":dataSetViewCount,\"Downloads\":dataSetDownloadNum,\n",
    "        \"Notebooks\":dataSetNotebookNum,\"Topics\":dataSetTopicNum,\"Number Of Files\":dataSetFileCount,\"File Size\":dataSetFileSize,\n",
    "        \"File Size Type\":dataSetFileSizeType,\"Author\":dataSetAuthorName,\"Location\":dataSetAuthorLocation,\n",
    "        \"Experience Num\":dataSetAuthorExperienceNum,\"Experience Num Type\":dataSetAuthorExperienceType,\"Followers\":dataSetAuthorFollowers,\n",
    "        \"Following\":dataSetAuthorFollowing,\"Owned Datasets\":dataSetAuthorDatasetCount,\"Code Helper\":dataSetAuthorCodeCount,\n",
    "        \"Discussion\":dataSetAuthorDiscussionCount,\"Competitions\":dataSetAuthorCompetitiveCount})\n",
    "    #\n",
    "    #7. exporting the DataFrame into a csv file\n",
    "    #\n",
    "    df.to_csv('All_Data_Stored_From_Kaggle.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5dd42",
   "metadata": {},
   "source": [
    "# Starting the crawling on the pages 2 - 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165aef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_of_database(2,160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d0127",
   "metadata": {},
   "source": [
    "# The dataframe of all the data\n",
    "importing the data from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5164cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>SubTitle</th>\n",
       "      <th>Version</th>\n",
       "      <th>Date Num</th>\n",
       "      <th>Date Type</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Views</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Notebooks</th>\n",
       "      <th>...</th>\n",
       "      <th>Author</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience Num</th>\n",
       "      <th>Experience Num Type</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>Owned Datasets</th>\n",
       "      <th>Code Helper</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>Competitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US Public Food Assistance</td>\n",
       "      <td>Where does it come from, who spends it, who ge...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>9.1</td>\n",
       "      <td>367</td>\n",
       "      <td>92,967</td>\n",
       "      <td>15,336</td>\n",
       "      <td>1,771</td>\n",
       "      <td>...</td>\n",
       "      <td>JohnM</td>\n",
       "      <td>Fort Worth, Texas, United States</td>\n",
       "      <td>7</td>\n",
       "      <td>years</td>\n",
       "      <td>1092</td>\n",
       "      <td>229</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>930</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kepler Exoplanet Search Results</td>\n",
       "      <td>10000 exoplanet candidates examined by the Kep...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>year</td>\n",
       "      <td>8.2</td>\n",
       "      <td>639</td>\n",
       "      <td>112,406</td>\n",
       "      <td>9,760</td>\n",
       "      <td>1,460</td>\n",
       "      <td>...</td>\n",
       "      <td>NASA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Things on Reddit</td>\n",
       "      <td>The top 100 products in each subreddit from 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>year</td>\n",
       "      <td>5.9</td>\n",
       "      <td>204</td>\n",
       "      <td>56,658</td>\n",
       "      <td>8,014</td>\n",
       "      <td>1,513</td>\n",
       "      <td>...</td>\n",
       "      <td>Aleksey Bilogur</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>1602</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>230</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18,393 Pitchfork Reviews</td>\n",
       "      <td>Pitchfork reviews from Jan 5, 1999 to Jan 8, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>year</td>\n",
       "      <td>7.1</td>\n",
       "      <td>364</td>\n",
       "      <td>65,139</td>\n",
       "      <td>9,916</td>\n",
       "      <td>1,753</td>\n",
       "      <td>...</td>\n",
       "      <td>Nolan Conaway</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal Crossing New Horizons Catalog</td>\n",
       "      <td>A comprehensive inventory of ACNH items, villa...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>month</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10356</td>\n",
       "      <td>145,172</td>\n",
       "      <td>12,857</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>Jessica Li</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>4</td>\n",
       "      <td>years</td>\n",
       "      <td>926</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Drug Seizues annually since 1970s</td>\n",
       "      <td>seizues of drugs from 1970s to pre covid period</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>month</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1,414</td>\n",
       "      <td>191</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Ram Jas Maurya</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>a</td>\n",
       "      <td>year</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>Fashion Anchor Cloth Pairs</td>\n",
       "      <td>Over 76k human-outfit item pairs for 5 categories</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>month</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9</td>\n",
       "      <td>341</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Kritanjali Jain</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>2</td>\n",
       "      <td>years</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>Prediction of music genre</td>\n",
       "      <td>Classify music into genres</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>month</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37</td>\n",
       "      <td>13,243</td>\n",
       "      <td>1,603</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>gaoyuan</td>\n",
       "      <td>Wellington, Wellington, New Zealand</td>\n",
       "      <td>5</td>\n",
       "      <td>months</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>Marketing Analytics</td>\n",
       "      <td>Practice Exploratory and Statistical Analysis ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>10.0</td>\n",
       "      <td>278</td>\n",
       "      <td>106,585</td>\n",
       "      <td>12,168</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>Jack Daoud</td>\n",
       "      <td>Boston, Massachusetts, United States</td>\n",
       "      <td>a</td>\n",
       "      <td>year</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>fer2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>year</td>\n",
       "      <td>2.9</td>\n",
       "      <td>342</td>\n",
       "      <td>142,157</td>\n",
       "      <td>23,940</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>Rohit Verma</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>4</td>\n",
       "      <td>years</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2737 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title  \\\n",
       "0                US Public Food Assistance   \n",
       "1          Kepler Exoplanet Search Results   \n",
       "2                         Things on Reddit   \n",
       "3                 18,393 Pitchfork Reviews   \n",
       "4     Animal Crossing New Horizons Catalog   \n",
       "...                                    ...   \n",
       "2732     Drug Seizues annually since 1970s   \n",
       "2733            Fashion Anchor Cloth Pairs   \n",
       "2734             Prediction of music genre   \n",
       "2735                   Marketing Analytics   \n",
       "2736                               fer2013   \n",
       "\n",
       "                                               SubTitle  Version  Date Num  \\\n",
       "0     Where does it come from, who spends it, who ge...        8         1   \n",
       "1     10000 exoplanet candidates examined by the Kep...        2         4   \n",
       "2     The top 100 products in each subreddit from 20...        1         4   \n",
       "3     Pitchfork reviews from Jan 5, 1999 to Jan 8, 2017        1         5   \n",
       "4     A comprehensive inventory of ACNH items, villa...        3         7   \n",
       "...                                                 ...      ...       ...   \n",
       "2732    seizues of drugs from 1970s to pre covid period        1         2   \n",
       "2733  Over 76k human-outfit item pairs for 5 categories        5         1   \n",
       "2734                         Classify music into genres        1         3   \n",
       "2735  Practice Exploratory and Statistical Analysis ...        1         1   \n",
       "2736                                                NaN        1         4   \n",
       "\n",
       "     Date Type  Usability  Rating    Views Downloads Notebooks  ...  \\\n",
       "0         year        9.1     367   92,967    15,336     1,771  ...   \n",
       "1         year        8.2     639  112,406     9,760     1,460  ...   \n",
       "2         year        5.9     204   56,658     8,014     1,513  ...   \n",
       "3         year        7.1     364   65,139     9,916     1,753  ...   \n",
       "4        month        8.2   10356  145,172    12,857        12  ...   \n",
       "...        ...        ...     ...      ...       ...       ...  ...   \n",
       "2732     month       10.0      11    1,414       191         3  ...   \n",
       "2733     month        6.9       9      341        44         0  ...   \n",
       "2734     month       10.0      37   13,243     1,603         9  ...   \n",
       "2735      year       10.0     278  106,585    12,168        67  ...   \n",
       "2736      year        2.9     342  142,157    23,940        59  ...   \n",
       "\n",
       "               Author                              Location  Experience Num  \\\n",
       "0               JohnM      Fort Worth, Texas, United States               7   \n",
       "1                NASA                                   NaN               0   \n",
       "2     Aleksey Bilogur     New York, New York, United States               5   \n",
       "3       Nolan Conaway     New York, New York, United States               5   \n",
       "4          Jessica Li     New York, New York, United States               4   \n",
       "...               ...                                   ...             ...   \n",
       "2732   Ram Jas Maurya               New Delhi, Delhi, India               a   \n",
       "2733  Kritanjali Jain            Mumbai, Maharashtra, India               2   \n",
       "2734          gaoyuan   Wellington, Wellington, New Zealand               5   \n",
       "2735       Jack Daoud  Boston, Massachusetts, United States               a   \n",
       "2736      Rohit Verma           Hyderabad, Telangana, India               4   \n",
       "\n",
       "     Experience Num Type Followers Following Owned Datasets Code Helper  \\\n",
       "0                  years      1092       229             28          44   \n",
       "1                    NaN         0         0            NaN           0   \n",
       "2                  years      1602        30             44         230   \n",
       "3                  years        10         0              5           9   \n",
       "4                  years       926        17             29          21   \n",
       "...                  ...       ...       ...            ...         ...   \n",
       "2732                year        35        17             47          18   \n",
       "2733               years        27         3              6          14   \n",
       "2734              months         1         0              1           1   \n",
       "2735                year        25        81              4           1   \n",
       "2736               years        92        12              9          17   \n",
       "\n",
       "      Discussion  Competitions  \n",
       "0            930           129  \n",
       "1              0             0  \n",
       "2            675             1  \n",
       "3              6             1  \n",
       "4            258             0  \n",
       "...          ...           ...  \n",
       "2732         233             1  \n",
       "2733           8             1  \n",
       "2734           1             3  \n",
       "2735          28             0  \n",
       "2736          83             1  \n",
       "\n",
       "[2737 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'All_Data_Stored_From_Kaggle.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ada74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
